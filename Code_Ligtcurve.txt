#Sliding Median_Chi2 Plot_Lightcurves....... 


import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Directory containing the folders with the files
main_directory = r"C:\Users\91912\Desktop\1234"

# Directory where the plots will be saved
plots_directory_chi2 = r"C:\Users\91912\Desktop\1234\Plots"
if not os.path.exists(plots_directory_chi2):
    os.makedirs(plots_directory_chi2)

# Specify the column names
column_names = ['TIME_KBJD', 'OBS_FLUX', 'OBS_FLUXerr', 'TIME_JD', 'NORM_FLUX', 'NORM_FLUXerr']

def sliding_median(arr, window_size):
    half_window = window_size // 2
    medians = []
    for i in range(len(arr)):
        if i < half_window:
            medians.append(np.median(arr[:i + half_window + 1]))
        elif i >= len(arr) - half_window:
            medians.append(np.median(arr[i - half_window:]))
        else:
            medians.append(np.median(arr[i - half_window:i + half_window + 1]))
    return medians

# Loop over all subdirectories in the main directory
for root, dirs, files in os.walk(main_directory):
    for file in files:
        # Check if the file ends with '_allLCs.txt'
        if file.endswith("_allLCs.txt"):
            file_path = os.path.join(root, file)
            df_2 = pd.read_csv(file_path, sep="\s+", skiprows=10, names=column_names, engine='python')

            # Clean the data
            df_2.dropna(inplace=True)
            df_2["Reduced_JD"] = pd.to_numeric(df_2["TIME_KBJD"], errors="coerce")
            df_2.dropna(subset=["Reduced_JD"], inplace=True)

            # Replacing fluxes below sigma/5 by the median of their surrounding points
            sigma = np.std(df_2["OBS_FLUX"])
            sigma_threshold = sigma / 5

            for i in range(len(df_2)):
                if np.abs(df_2["OBS_FLUX"].iloc[i] - df_2["OBS_FLUX"].iloc[i]) > sigma_threshold:
                    aux = np.arange(i-10, i+11)
                    aux = aux[(aux >= 0) & (aux < len(df_2))]  # Exclude indices outside the valid range
                    df_2.loc[i, "OBS_FLUX"] = np.median(df_2["OBS_FLUX"].iloc[aux])

            # Normalizing by sliding median technique
            window_size = len(df_2) // 4
            df_2["Normalized_FLUX"] = df_2["OBS_FLUX"] / sliding_median(df_2["OBS_FLUX"], window_size)

            # Clean the df_2["Normalized_FLUX"]
            df_2.dropna(subset=["Normalized_FLUX"], inplace=True)

            # Define box sizes and compute chi-square values
            box_sizes = np.arange(10, 101, 1)
            chi2_values = np.zeros_like(box_sizes, dtype=float)

            for i, bz in enumerate(box_sizes):
                flux_aux = np.zeros_like(df_2["Normalized_FLUX"])
                for j, flux in enumerate(df_2["Normalized_FLUX"]):
                    if j < bz + 1:
                        flux_aux[j] = np.median(df_2["Normalized_FLUX"][:j + bz])
                    elif j > len(df_2["Normalized_FLUX"]) - 1 - (bz + 1):
                        flux_aux[j] = np.median(df_2["Normalized_FLUX"][j - bz:])
                    else:
                        flux_aux[j] = np.median(df_2["Normalized_FLUX"][j - bz:j + bz + 1])
                chi2_values[i] = np.sum(((df_2["Normalized_FLUX"] - flux_aux) ** 2) / df_2["OBS_FLUXerr"] ** 2)

            # Find the maximum chi-square value and its corresponding box size
            max_chi2 = np.max(chi2_values)
            max_chi2_box_size = box_sizes[np.argmax(chi2_values)]

            # Plot the chi-square versus box size with cool color scheme
            plt.style.use('dark_background')
            plt.figure(figsize=(8, 4))
            plt.scatter(box_sizes, chi2_values, marker='o', s=10, color='deepskyblue', edgecolors='white')
            plt.axvline(max_chi2_box_size, color='red', linestyle='--', label=f'Max Chi-Square: {max_chi2:.2f}')
            plt.xlabel("Box Size (Number of Points)")
            plt.ylabel("Chi-Square")
            plt.title("Chi-Square versus Box Size for {}".format(file))
            plt.legend()
            plt.grid(color='gray', linestyle='--', linewidth=0.5)
            plt.savefig(os.path.join(plots_directory_chi2, file.replace("_allLCs.txt", "_chi2_plot.png")), dpi=300)
            plt.close()

            # Using the maximum chi-square value, create the phase-folded light curve plot
            Pe = 0  # Set default values in case the '_res.txt' file is not found
            T0 = 0
            for res_file in files:
                # Check if the file ends with '_res.txt'
                if res_file.endswith("_res.txt"):
                    file_path = os.path.join(root, res_file)

                    # Read the 7th line from the file
                    df_res = pd.read_csv(file_path, skiprows=7, nrows=1, header=None, engine='python')

                    # Split the string into parts
                    parts = df_res.iloc[0, 0].split()

                    # Check the number of parts
                    if len(parts) == 2:
                        # Extract the two parts and convert them to floats
                        Pe = float(parts[0])
                        T0 = float(parts[1])
                        break

            tvar = df_2["TIME_JD"] - T0 + Pe / 4.
            phase = (tvar / Pe) - np.floor(tvar / Pe)
            phase_000 = (tvar / Pe) % 1.0
            phase_025 = (tvar / Pe - 0.25) % 1.

            # Plot phase 0.0
            plt.figure(figsize=(8, 4))
            plt.plot(phase_000.values, df_2["Normalized_FLUX"].values, 'o', markersize=2, markerfacecolor='blue', markeredgecolor='white')
            plt.xlabel("Phase (0.0)")
            plt.ylabel("Normalized Flux")
            plt.title("Phase-folded Light Curve (Phase 0.0)")
            plt.grid(True)
            plt.savefig(os.path.join(plots_directory_chi2, file.replace("_allLCs.txt", "_phase_folded_000.png")), dpi=300)
            plt.close()

            # Plot phase 0.25
            plt.figure(figsize=(8, 4))
            plt.plot(phase_025.values, df_2["Normalized_FLUX"].values, 'o', markersize=2, markerfacecolor='blue', markeredgecolor='white')
            plt.xlabel("Phase (0.25)")
            plt.ylabel("Normalized Flux")
            plt.title("Phase-folded Light Curve (Phase 0.25)")
            plt.grid(True)
            plt.savefig(os.path.join(plots_directory_chi2, file.replace("_allLCs.txt", "_phase_folded_025.png")), dpi=300)
            plt.close()

            # Additional Plot using the style settings
            plt.style.use('dark_background')
            plt.figure(figsize=(8, 4))
            plt.plot(phase.values, df_2["NORM_FLUX"].values, 'o', markersize=2, markerfacecolor='blue', markeredgecolor='white')
            plt.xlabel("Phase")
            plt.ylabel("Normalized Flux")
            plt.title("Phase-folded Light Curve")
            plt.grid(color='gray', linestyle='--', linewidth=0.5)
            plt.gca().set_facecolor('black')
            plt.savefig(os.path.join(plots_directory_chi2, file.replace("_allLCs.txt", "_phase_folded_plot.png")), dpi=300)
            plt.close()


#Code for saving sliding median values in Text Files:
import os
import pandas as pd
import numpy as np
from scipy.optimize import curve_fit
from sklearn.metrics import r2_score

# Directory containing the folders with the files
main_directory = r"C:\Users\91912\Desktop\953 CLASSIFICATIONS\Fourth 42"

# Specify the column names
column_names = ['TIME_KBJD', 'OBS_FLUX', 'OBS_FLUXerr', 'TIME_JD', 'NORM_FLUX', 'NORM_FLUXerr']

# Define the sliding_median function
def sliding_median(arr, window_size):
    half_window = window_size // 2
    medians = []
    for i in range(len(arr)):
        if i < half_window:
            medians.append(np.median(arr[:i + half_window + 1]))
        elif i >= len(arr) - half_window:
            medians.append(np.median(arr[i - half_window:]))
        else:
            medians.append(np.median(arr[i - half_window:i + half_window + 1]))
    return medians

# Create an empty list to store the results
results = []

# Loop over all subdirectories in the main directory
for root, dirs, files in os.walk(main_directory):
    for file in files:
        # Check if the file ends with '_allLCs.txt'
        if file.endswith("_allLCs.txt"):
            file_path = os.path.join(root, file)
            df_2 = pd.read_csv(file_path, sep="\s+", skiprows=10, names=column_names, engine='python')

            # Clean the data
            df_2.dropna(inplace=True)
            df_2["Reduced_JD"] = pd.to_numeric(df_2["TIME_KBJD"], errors="coerce")
            df_2.dropna(subset=["Reduced_JD"], inplace=True)

            # Replacing fluxes below sigma/5 by the median of their surrounding points
            sigma = np.std(df_2["OBS_FLUX"])
            sigma_threshold = sigma / 5

            for i in range(len(df_2)):
                if np.abs(df_2["OBS_FLUX"].iloc[i] - df_2["OBS_FLUX"].iloc[i]) > sigma_threshold:
                    aux = np.arange(i-10, i+11)
                    aux = aux[(aux >= 0) & (aux < len(df_2))]  # Exclude indices outside the valid range
                    df_2.loc[i, "OBS_FLUX"] = np.median(df_2["OBS_FLUX"].iloc[aux])

            # Normalizing by sliding median technique
            window_size = len(df_2) // 4
            df_2["Normalized_FLUX"] = df_2["OBS_FLUX"] / sliding_median(df_2["OBS_FLUX"], window_size)

            # Define box sizes and compute chi-square values
            box_sizes = np.arange(10, 101, 1)
            chi2_values = np.zeros_like(box_sizes, dtype=float)

            for i, bz in enumerate(box_sizes):
                flux_aux = np.zeros_like(df_2["Normalized_FLUX"])
                for j, flux in enumerate(df_2["Normalized_FLUX"]):
                    if j < bz + 1:
                        flux_aux[j] = np.median(df_2["Normalized_FLUX"][:j + bz])
                    elif j > len(df_2["Normalized_FLUX"]) - 1 - (bz + 1):
                        flux_aux[j] = np.median(df_2["Normalized_FLUX"][j - bz:])
                    else:
                        flux_aux[j] = np.median(df_2["Normalized_FLUX"][j - bz:j + bz + 1])
                chi2_values[i] = np.sum(((df_2["Normalized_FLUX"] - flux_aux) ** 2) / df_2["OBS_FLUXerr"] ** 2)

            # Save chi-square values in a text file with target name
            target = os.path.basename(file_path).replace("_allLCs.txt", "")
            output_file = os.path.join(main_directory, target + "_chi2_values.txt")
            np.savetxt(output_file, chi2_values, fmt="%.8f")

#Code for Classififcation:


import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit, OptimizeWarning
from sklearn.metrics import r2_score

# Define the damping sinusoidal function with separate decay factors for the sinusoidal and exponential terms
def damping_sinusoidal(x, A, w, phi, decay):
    return A * np.exp(-decay*x) * np.sin(w * x + phi)

# Directory containing the folders with the files
main_directory = r"C:\Users\91912\Desktop\100"

# Define the different ranges of x_data
x_ranges = [(10, 51, 1), (10, 71, 1), (10, 91, 1)]

# Create empty lists to store the results
results = []

# Loop over all subdirectories in the main directory
for root, dirs, files in os.walk(main_directory):
    for file in files:
        # Check if the file ends with '_chi2_values.txt'
        if file.endswith("_chi2_values.txt"):
            file_path = os.path.join(root, file)
            
            # Read the chi-square values from the file
            y_data = np.loadtxt(file_path)
            
            # Calculate the baseline as the mean of the y_data
            baseline = np.mean(y_data)
            
            # Shift the y_data by the baseline value
            y_data -= baseline
            
            try:
                # Fit the damping sinusoidal function to the data with initial parameter estimates
                p0_damping_sinusoidal = [np.max(y_data), 0.1, 0, 0.01]  # Provide initial estimates for A, w, phi, decay
                popt_damping_sinusoidal, _ = curve_fit(
                    damping_sinusoidal, np.arange(len(y_data)), y_data, p0=p0_damping_sinusoidal, maxfev=50000
                )

                # Fit a polynomial function to the data
                polynomial_degree = 4  # You can adjust the degree of the polynomial fit
                popt_polynomial = np.polyfit(np.arange(len(y_data)), y_data, polynomial_degree)

                # Generate predictions using the optimized parameters
                y_pred_damping_sinusoidal = damping_sinusoidal(
                    np.arange(len(y_data)), *popt_damping_sinusoidal
                ) + baseline  # Add the baseline back to the predictions
                y_pred_polynomial = np.polyval(popt_polynomial, np.arange(len(y_data))) + baseline  # Add the baseline back to the predictions

                # Calculate R-squared values
                r_squared_damping_s = r2_score(y_data + baseline, y_pred_damping_sinusoidal)
                r_squared_p = r2_score(y_data + baseline, y_pred_polynomial)

                # Compare R-squared values and apply fitting thresholds
                if r_squared_damping_s > 0.9 and r_squared_p <= 0.6 and r_squared_damping_s > r_squared_p:
                    classification = "C"
                elif r_squared_p > 0.8 and r_squared_damping_s > 0.5 and r_squared_p > r_squared_damping_s:
                    classification = "D"
                elif r_squared_damping_s < 0.7 and r_squared_p < 0.5:
                    classification = "S.D"
                else:
                    classification = "D"

                # Append the classification result and R-squared values to the results list
                results.append({"File Name": file.replace("_chi2_values.txt", ""), "Classification": classification,
                                "R-squared (Damping Sinusoidal)": r_squared_damping_s,
                                "R-squared (Polynomial)": r_squared_p})

                # Plot the fitted curves with cool colors
                plt.figure(figsize=(6, 4))
                plt.plot(np.arange(len(y_data)), y_data + baseline, 'bo-', label="Original Data", markersize=4)
                plt.plot(np.arange(len(y_data)), y_pred_damping_sinusoidal, 'g--', label="Damping Sinusoidal Fit", linewidth=1.5)
                plt.plot(np.arange(len(y_data)), y_pred_polynomial, 'r-.', label=f"Polynomial Fit (Degree {polynomial_degree})", linewidth=1.5)
                plt.legend(fontsize=8)
                plt.xlabel("X", fontsize=10)
                plt.ylabel("Y", fontsize=10)
                
                # Add the classification to the plot title
                plt.title(f"Target: {file.replace('_chi2_values.txt', '')}, Classification: {classification}", fontsize=12)
                
                plt.grid(True)
                plt.tight_layout()
                plt.show()  # Display the plots on the screen instead of saving to files
                plt.close()

                # Display the R-squared values for each target
                print(f"Target: {file.replace('_chi2_values.txt', '')}")
                print(f"R-squared (Damping Sinusoidal): {r_squared_damping_s}")
                print(f"R-squared (Polynomial): {r_squared_p}")
                print("--------")

            except (RuntimeError, OptimizeWarning):
                # If curve fitting fails, classify as "D"
                classification = "D"
                
                # Append the classification result with R-squared values as None
                results.append({"File Name": file.replace("_chi2_values.txt", ""), "Classification": classification,
                                "R-squared (Damping Sinusoidal)": None,
                                "R-squared (Polynomial)": None})

# Create a DataFrame to store the results
results_df = pd.DataFrame(results)

# Determine the repeated classification for each target
repeated_classifications = results_df.groupby("File Name")["Classification"].apply(
    lambda x: x.value_counts().idxmax()
)

# Create a DataFrame to store the repeated classifications
repeated_classifications_df = pd.DataFrame(
    {"File Name": repeated_classifications.index, "Classification": repeated_classifications.values}
)

# Define the path to the output Excel file
output_file = os.path.join(main_directory, "Mahadev01.xlsx")

# Write the DataFrame to the Excel file
repeated_classifications_df.to_excel(output_file, index=False)

print("Fitted results have been written to 'Mahadev01.xlsx'")
